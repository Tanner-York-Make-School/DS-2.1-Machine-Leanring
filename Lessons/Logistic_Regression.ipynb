{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Logistic Regression?\n",
    "- Logistic regression is another type of classifier, which is different from linear regression\n",
    "- Logistic regression predicts whether something is True or False, and the plot is an S-curve that goes from 0 to 1 (probability of False to True)\n",
    "- How is it different from SVM?\n",
    "    - SVM can not tell us what the probability is of being classified in a given category\n",
    "    - For example, going back to the example we used in our SVM class, if my Serotonin is 3 and my Dopamine is 6, what is the chance that I would be considered happy? 90 percent? 60 percent? etc...\n",
    "- Logistic Regression tell us this information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Fit a Logistic Regression Classifier on diabetes.csv\n",
    "**In groups of 3, complete the following steps:**\n",
    "- Load the dataset: pd.read_csv('diabetes.csv')\n",
    "- Use these features: feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "- Split the data to train and test: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "- Obtain the statistics of y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../Data/Diabetes.csv')\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "X = df[feature_cols]\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63247571, 0.36752429],\n",
       "       [0.71643656, 0.28356344],\n",
       "       [0.71104114, 0.28895886],\n",
       "       [0.5858938 , 0.4141062 ],\n",
       "       [0.84103973, 0.15896027],\n",
       "       [0.82934844, 0.17065156],\n",
       "       [0.50110974, 0.49889026],\n",
       "       [0.48658459, 0.51341541],\n",
       "       [0.72321388, 0.27678612],\n",
       "       [0.32810562, 0.67189438],\n",
       "       [0.64244443, 0.35755557],\n",
       "       [0.25912035, 0.74087965],\n",
       "       [0.63949765, 0.36050235],\n",
       "       [0.76987637, 0.23012363],\n",
       "       [0.57345769, 0.42654231],\n",
       "       [0.80896485, 0.19103515],\n",
       "       [0.54236399, 0.45763601],\n",
       "       [0.8809859 , 0.1190141 ],\n",
       "       [0.56071047, 0.43928953],\n",
       "       [0.63038849, 0.36961151],\n",
       "       [0.55812011, 0.44187989],\n",
       "       [0.62388338, 0.37611662],\n",
       "       [0.80183978, 0.19816022],\n",
       "       [0.58322696, 0.41677304],\n",
       "       [0.84451719, 0.15548281],\n",
       "       [0.7468329 , 0.2531671 ],\n",
       "       [0.90256923, 0.09743077],\n",
       "       [0.30366288, 0.69633712],\n",
       "       [0.84641691, 0.15358309],\n",
       "       [0.7802164 , 0.2197836 ],\n",
       "       [0.56905168, 0.43094832],\n",
       "       [0.65783942, 0.34216058],\n",
       "       [0.77603886, 0.22396114],\n",
       "       [0.61926457, 0.38073543],\n",
       "       [0.86657866, 0.13342134],\n",
       "       [0.61209784, 0.38790216],\n",
       "       [0.52950297, 0.47049703],\n",
       "       [0.83795257, 0.16204743],\n",
       "       [0.70451824, 0.29548176],\n",
       "       [0.69081839, 0.30918161],\n",
       "       [0.72700295, 0.27299705],\n",
       "       [0.61183417, 0.38816583],\n",
       "       [0.72646557, 0.27353443],\n",
       "       [0.71118959, 0.28881041],\n",
       "       [0.36528086, 0.63471914],\n",
       "       [0.97634749, 0.02365251],\n",
       "       [0.84179352, 0.15820648],\n",
       "       [0.76981625, 0.23018375],\n",
       "       [0.6515407 , 0.3484593 ],\n",
       "       [0.72419959, 0.27580041],\n",
       "       [0.66735896, 0.33264104],\n",
       "       [0.75119404, 0.24880596],\n",
       "       [0.25510488, 0.74489512],\n",
       "       [0.60998536, 0.39001464],\n",
       "       [0.58374455, 0.41625545],\n",
       "       [0.86424313, 0.13575687],\n",
       "       [0.81104624, 0.18895376],\n",
       "       [0.35222318, 0.64777682],\n",
       "       [0.81077869, 0.18922131],\n",
       "       [0.94314096, 0.05685904],\n",
       "       [0.36008453, 0.63991547],\n",
       "       [0.53363618, 0.46636382],\n",
       "       [0.8749028 , 0.1250972 ],\n",
       "       [0.73042398, 0.26957602],\n",
       "       [0.75080896, 0.24919104],\n",
       "       [0.69429604, 0.30570396],\n",
       "       [0.53623776, 0.46376224],\n",
       "       [0.79036905, 0.20963095],\n",
       "       [0.57152171, 0.42847829],\n",
       "       [0.59237736, 0.40762264],\n",
       "       [0.79830904, 0.20169096],\n",
       "       [0.72972934, 0.27027066],\n",
       "       [0.73744144, 0.26255856],\n",
       "       [0.42761737, 0.57238263],\n",
       "       [0.54532959, 0.45467041],\n",
       "       [0.72283848, 0.27716152],\n",
       "       [0.41998719, 0.58001281],\n",
       "       [0.58400512, 0.41599488],\n",
       "       [0.72723899, 0.27276101],\n",
       "       [0.65900777, 0.34099223],\n",
       "       [0.45373422, 0.54626578],\n",
       "       [0.62069277, 0.37930723],\n",
       "       [0.7007795 , 0.2992205 ],\n",
       "       [0.89940831, 0.10059169],\n",
       "       [0.67127398, 0.32872602],\n",
       "       [0.54898637, 0.45101363],\n",
       "       [0.83963021, 0.16036979],\n",
       "       [0.5103025 , 0.4896975 ],\n",
       "       [0.36769492, 0.63230508],\n",
       "       [0.59261596, 0.40738404],\n",
       "       [0.80205603, 0.19794397],\n",
       "       [0.80301979, 0.19698021],\n",
       "       [0.75536792, 0.24463208],\n",
       "       [0.88852815, 0.11147185],\n",
       "       [0.5841403 , 0.4158597 ],\n",
       "       [0.78438144, 0.21561856],\n",
       "       [0.45875471, 0.54124529],\n",
       "       [0.51196398, 0.48803602],\n",
       "       [0.35347233, 0.64652767],\n",
       "       [0.66059342, 0.33940658],\n",
       "       [0.45736573, 0.54263427],\n",
       "       [0.83786176, 0.16213824],\n",
       "       [0.6221259 , 0.3778741 ],\n",
       "       [0.88688713, 0.11311287],\n",
       "       [0.65218013, 0.34781987],\n",
       "       [0.65957216, 0.34042784],\n",
       "       [0.8209015 , 0.1790985 ],\n",
       "       [0.78675188, 0.21324812],\n",
       "       [0.85289054, 0.14710946],\n",
       "       [0.76985898, 0.23014102],\n",
       "       [0.81595408, 0.18404592],\n",
       "       [0.47775351, 0.52224649],\n",
       "       [0.52900634, 0.47099366],\n",
       "       [0.71115752, 0.28884248],\n",
       "       [0.50674921, 0.49325079],\n",
       "       [0.58255527, 0.41744473],\n",
       "       [0.77084992, 0.22915008],\n",
       "       [0.72977089, 0.27022911],\n",
       "       [0.80756076, 0.19243924],\n",
       "       [0.2501287 , 0.7498713 ],\n",
       "       [0.53499907, 0.46500093],\n",
       "       [0.3354546 , 0.6645454 ],\n",
       "       [0.57901401, 0.42098599],\n",
       "       [0.46435966, 0.53564034],\n",
       "       [0.83965298, 0.16034702],\n",
       "       [0.8564314 , 0.1435686 ],\n",
       "       [0.61857574, 0.38142426],\n",
       "       [0.66172686, 0.33827314],\n",
       "       [0.6369935 , 0.3630065 ],\n",
       "       [0.87157469, 0.12842531],\n",
       "       [0.71666307, 0.28333693],\n",
       "       [0.95994442, 0.04005558],\n",
       "       [0.81518861, 0.18481139],\n",
       "       [0.33283053, 0.66716947],\n",
       "       [0.53647126, 0.46352874],\n",
       "       [0.51284318, 0.48715682],\n",
       "       [0.80089206, 0.19910794],\n",
       "       [0.54138349, 0.45861651],\n",
       "       [0.76783279, 0.23216721],\n",
       "       [0.81630733, 0.18369267],\n",
       "       [0.73608006, 0.26391994],\n",
       "       [0.62507031, 0.37492969],\n",
       "       [0.87083494, 0.12916506],\n",
       "       [0.58586087, 0.41413913],\n",
       "       [0.57539142, 0.42460858],\n",
       "       [0.86167809, 0.13832191],\n",
       "       [0.79218306, 0.20781694],\n",
       "       [0.70522301, 0.29477699],\n",
       "       [0.84174901, 0.15825099],\n",
       "       [0.63983766, 0.36016234],\n",
       "       [0.76258551, 0.23741449],\n",
       "       [0.56649311, 0.43350689],\n",
       "       [0.79380119, 0.20619881],\n",
       "       [0.76837662, 0.23162338],\n",
       "       [0.38888459, 0.61111541],\n",
       "       [0.80268991, 0.19731009],\n",
       "       [0.19928502, 0.80071498],\n",
       "       [0.82191509, 0.17808491],\n",
       "       [0.63511265, 0.36488735],\n",
       "       [0.21381357, 0.78618643],\n",
       "       [0.55919386, 0.44080614],\n",
       "       [0.63440346, 0.36559654],\n",
       "       [0.88239862, 0.11760138],\n",
       "       [0.77156675, 0.22843325],\n",
       "       [0.52134931, 0.47865069],\n",
       "       [0.78679475, 0.21320525],\n",
       "       [0.48501479, 0.51498521],\n",
       "       [0.83877506, 0.16122494],\n",
       "       [0.76259881, 0.23740119],\n",
       "       [0.70625609, 0.29374391],\n",
       "       [0.83329952, 0.16670048],\n",
       "       [0.51283474, 0.48716526],\n",
       "       [0.70030106, 0.29969894],\n",
       "       [0.55348957, 0.44651043],\n",
       "       [0.49830098, 0.50169902],\n",
       "       [0.70753494, 0.29246506],\n",
       "       [0.38263772, 0.61736228],\n",
       "       [0.58406005, 0.41593995],\n",
       "       [0.74179055, 0.25820945],\n",
       "       [0.8258032 , 0.1741968 ],\n",
       "       [0.66480459, 0.33519541],\n",
       "       [0.30393175, 0.69606825],\n",
       "       [0.67545632, 0.32454368],\n",
       "       [0.64269574, 0.35730426],\n",
       "       [0.7663053 , 0.2336947 ],\n",
       "       [0.76261476, 0.23738524],\n",
       "       [0.61590682, 0.38409318],\n",
       "       [0.75308588, 0.24691412],\n",
       "       [0.72045448, 0.27954552],\n",
       "       [0.81498826, 0.18501174],\n",
       "       [0.7377638 , 0.2622362 ],\n",
       "       [0.72143074, 0.27856926]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_precent = log_reg.predict_proba(X_test)\n",
    "y_pred_precent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5427609427609426\n",
      "0.3072916666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(r2_score(y_pred, y_test))\n",
    "print(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "A confusion matrix is a table that is used to describe the performance of a classifier on a set of test data where we know the true vales. Essentially, we use it to check how well our classifier's predicted values matched against the known values of the same data.\n",
    "\n",
    "The confusion matrix itself is a simple 2x2 matrix, but it's important we go over the terminology of each row/column in the matrix:\n",
    "\n",
    "**True Positives (TP):** we correctly predicted a positive outcome (i.e. someone has diabetes, and we correctly predicted it)\n",
    "\n",
    "**True Negatives (TN):** we correctly predicted a negative outcome (i.e. someone does not have diabetes, and we correctly predicted it)\n",
    "\n",
    "**False Positives (FP):** we incorrectly predicted a positive outcome (i.e. someone does not diabetes, and we incorrectly said that they did)\n",
    "\n",
    "**False Negatives (FN):** we incorrectly predicted a negative outcome (i.e. someone has diabetes, and we incorrectly said that they do not)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Write a function that calculates the confusion matrix for the Pima Diabetes dataset\n",
    "- How many 0s (no diabetes) in y_test are predicted correctly as 0 (no diabetes) in y_pred?\n",
    "    - True Positives\n",
    "- How many 0s (no diabetes) in y_test are predicted incorrectly as 1 (diabetes) in y_pred?\n",
    "    - False Positive\n",
    "- How many 1s (diabetes) in y_test are predicted incorrectly as 0 (no diabetes) in y_pred?\n",
    "    - False Negative\n",
    "- How many 1s (diabetes) in y_test are predicted correctly 1 (diabetes) in y_pred?\n",
    "    - True Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118.  12.]\n",
      " [ 47.  15.]]\n"
     ]
    }
   ],
   "source": [
    "def compare_ys(y_test, y_pred, test_value, pred_value):\n",
    "    count = 0\n",
    "    for i, j in zip(y_test, y_pred):\n",
    "        if i == test_value and j == pred_value:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def confusion_matrix(y_test, y_pred):\n",
    "    conf_matrix  = np.zeros((2, 2))\n",
    "    for row_index in [0, 1]:\n",
    "        for column_index in [0, 1]:\n",
    "            counter = 0\n",
    "            for (test_index, pred_index) in zip(y_test, y_pred):\n",
    "                if (test_index == row_index) & (pred_index == column_index):\n",
    "                        counter += 1\n",
    "            conf_matrix[row_index, column_index] = counter \n",
    "    return conf_matrix\n",
    "    \n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easier way to compute elements of Confusion Matrix using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
